{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VqsIzVck2-V",
        "outputId": "63603789-61b1-4475-e916-c22c5b03d782"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pygam\n",
            "  Downloading pygam-0.9.1-py3-none-any.whl (522 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m522.0/522.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.10/dist-packages (from pygam) (1.25.2)\n",
            "Requirement already satisfied: progressbar2<5.0.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pygam) (4.2.0)\n",
            "Requirement already satisfied: scipy<1.12,>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from pygam) (1.11.4)\n",
            "Requirement already satisfied: python-utils>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from progressbar2<5.0.0,>=4.2.0->pygam) (3.8.2)\n",
            "Requirement already satisfied: typing-extensions>3.10.0.2 in /usr/local/lib/python3.10/dist-packages (from python-utils>=3.0.0->progressbar2<5.0.0,>=4.2.0->pygam) (4.11.0)\n",
            "Installing collected packages: pygam\n",
            "Successfully installed pygam-0.9.1\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.2)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.25.2)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.11.4)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (2.0.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pygam\n",
        "!pip install statsmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3ZU1Yiagmze",
        "outputId": "ab145a69-8072-4685-cda0-223e40a9e818"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ayJyXpssyGZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhvQy8QOKThV"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "K6uGz7VfGeIm",
        "outputId": "bb1ff499-b3fa-42c6-d978-df2c8b55790c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 22614,\n  \"fields\": [\n    {\n      \"column\": \"H\\u01b0\\u1edbng\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Nam\",\n          \"T\\u00e2y Nam\",\n          \"\\u0110\\u00f4ng Nam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0110\\u01b0\\u1eddng tr\\u01b0\\u1edbc nh\\u00e0(m)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.078083801385613,\n        \"min\": 0.0,\n        \"max\": 435.0,\n        \"num_unique_values\": 63,\n        \"samples\": [\n          48.0,\n          39.0,\n          30.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lo\\u1ea1i BDS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ph\\u00e1p l\\u00fd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S\\u1ed1 l\\u1ea7u\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 55,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          6,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S\\u1ed1 ph\\u00f2ng ng\\u1ee7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 120,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          27,\n          40\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gi\\u00e1(T\\u1ef7)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45.80013847194144,\n        \"min\": 0.023,\n        \"max\": 1996.0,\n        \"num_unique_values\": 973,\n        \"samples\": [\n          6.05,\n          37.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Di\\u1ec7n t\\u00edch(m2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 131.0345748933564,\n        \"min\": 1.0,\n        \"max\": 982.0,\n        \"num_unique_values\": 674,\n        \"samples\": [\n          926.0,\n          390.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T\\u1ec9nh/ Th\\u00e0nh ph\\u1ed1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          9,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Qu\\u1eadn/ Huy\\u1ec7n\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 101,\n        \"samples\": [\n          \"B\\u1ea3o L\\u00e2m\",\n          \"B\\u00ecnh Th\\u1ee7y\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"M\\u1eadt \\u0111\\u1ed9 d\\u00e2n s\\u1ed1 (ng\\u01b0\\u1eddi/km\\u00b2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 159.1531845278029,\n        \"min\": 1.063,\n        \"max\": 996.0,\n        \"num_unique_values\": 99,\n        \"samples\": [\n          6.718,\n          32.439\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GDPD(%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.208191439681489,\n        \"min\": -9.28,\n        \"max\": 10.35,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          7.03,\n          5.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4a9ae2f6-7731-4ad8-9d84-0d0d2a5ab78e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hướng</th>\n",
              "      <th>Đường trước nhà(m)</th>\n",
              "      <th>Loại BDS</th>\n",
              "      <th>Pháp lý</th>\n",
              "      <th>Số lầu</th>\n",
              "      <th>Số phòng ngủ</th>\n",
              "      <th>Giá(Tỷ)</th>\n",
              "      <th>Diện tích(m2)</th>\n",
              "      <th>Tỉnh/ Thành phố</th>\n",
              "      <th>Quận/ Huyện</th>\n",
              "      <th>Mật độ dân số (người/km²)</th>\n",
              "      <th>GDPD(%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>_</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>10.5</td>\n",
              "      <td>60.0</td>\n",
              "      <td>4</td>\n",
              "      <td>Hà Đông</td>\n",
              "      <td>8.021</td>\n",
              "      <td>6.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tây Nam</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5.3</td>\n",
              "      <td>245.0</td>\n",
              "      <td>12</td>\n",
              "      <td>Trảng Bom</td>\n",
              "      <td>1.079</td>\n",
              "      <td>5.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>_</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>9.1</td>\n",
              "      <td>91.0</td>\n",
              "      <td>10</td>\n",
              "      <td>Sơn Trà</td>\n",
              "      <td>2.483</td>\n",
              "      <td>2.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>_</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>46.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>8</td>\n",
              "      <td>Thủ Đức</td>\n",
              "      <td>4.791</td>\n",
              "      <td>5.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>_</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>11.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>8</td>\n",
              "      <td>Bình Thạnh</td>\n",
              "      <td>23.998</td>\n",
              "      <td>5.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22609</th>\n",
              "      <td>Nam</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>8.5</td>\n",
              "      <td>63.0</td>\n",
              "      <td>4</td>\n",
              "      <td>Hà Đông</td>\n",
              "      <td>8.021</td>\n",
              "      <td>6.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22610</th>\n",
              "      <td>_</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>9.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>4</td>\n",
              "      <td>Hà Đông</td>\n",
              "      <td>8.021</td>\n",
              "      <td>6.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22611</th>\n",
              "      <td>_</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>11.5</td>\n",
              "      <td>201.0</td>\n",
              "      <td>4</td>\n",
              "      <td>Đông Anh</td>\n",
              "      <td>2.186</td>\n",
              "      <td>6.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22612</th>\n",
              "      <td>_</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>36.0</td>\n",
              "      <td>4</td>\n",
              "      <td>Bắc Từ Liêm</td>\n",
              "      <td>7.529</td>\n",
              "      <td>6.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22613</th>\n",
              "      <td>Tây Bắc</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3.2</td>\n",
              "      <td>65.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Dĩ An</td>\n",
              "      <td>6.718</td>\n",
              "      <td>5.97</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22614 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a9ae2f6-7731-4ad8-9d84-0d0d2a5ab78e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4a9ae2f6-7731-4ad8-9d84-0d0d2a5ab78e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4a9ae2f6-7731-4ad8-9d84-0d0d2a5ab78e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-710f394e-c252-487b-8067-9d49213877e7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-710f394e-c252-487b-8067-9d49213877e7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-710f394e-c252-487b-8067-9d49213877e7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e269f16f-807e-473e-96a6-c1b8e558c515\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e269f16f-807e-473e-96a6-c1b8e558c515 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         Hướng  Đường trước nhà(m)  Loại BDS  Pháp lý  Số lầu  Số phòng ngủ  \\\n",
              "0            _                30.0         1        1       6             6   \n",
              "1      Tây Nam                30.0         1        1       1             1   \n",
              "2            _                15.0         1        1       3             4   \n",
              "3            _                30.0         1        1       5             5   \n",
              "4            _                10.0         2        1       3             4   \n",
              "...        ...                 ...       ...      ...     ...           ...   \n",
              "22609      Nam                13.0         0        1       5             6   \n",
              "22610        _                 7.0         0        1       5             6   \n",
              "22611        _                 4.0         0        1       3             3   \n",
              "22612        _                 5.0         0        0       5             4   \n",
              "22613  Tây Bắc                 7.0         0        1       2             3   \n",
              "\n",
              "       Giá(Tỷ)  Diện tích(m2)  Tỉnh/ Thành phố  Quận/ Huyện  \\\n",
              "0         10.5           60.0                4      Hà Đông   \n",
              "1          5.3          245.0               12    Trảng Bom   \n",
              "2          9.1           91.0               10      Sơn Trà   \n",
              "3         46.0          180.0                8      Thủ Đức   \n",
              "4         11.0           82.0                8   Bình Thạnh   \n",
              "...        ...            ...              ...          ...   \n",
              "22609      8.5           63.0                4      Hà Đông   \n",
              "22610      9.0           77.0                4      Hà Đông   \n",
              "22611     11.5          201.0                4     Đông Anh   \n",
              "22612      3.7           36.0                4  Bắc Từ Liêm   \n",
              "22613      3.2           65.0                1        Dĩ An   \n",
              "\n",
              "       Mật độ dân số (người/km²)  GDPD(%)  \n",
              "0                          8.021     6.27  \n",
              "1                          1.079     5.30  \n",
              "2                          2.483     2.58  \n",
              "3                          4.791     5.81  \n",
              "4                         23.998     5.81  \n",
              "...                          ...      ...  \n",
              "22609                      8.021     6.27  \n",
              "22610                      8.021     6.27  \n",
              "22611                      2.186     6.27  \n",
              "22612                      7.529     6.27  \n",
              "22613                      6.718     5.97  \n",
              "\n",
              "[22614 rows x 12 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=pd.read_csv('DataCleaned.csv',sep=';',header=0)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3eo_De9Igqd",
        "outputId": "45e589d1-0be3-4140-8ba5-3717a79acc0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hướng                         object\n",
            "Đường trước nhà(m)           float64\n",
            "Loại BDS                       int64\n",
            "Pháp lý                        int64\n",
            "Số lầu                         int64\n",
            "Số phòng ngủ                   int64\n",
            "Giá(Tỷ)                      float64\n",
            "Diện tích(m2)                float64\n",
            "Tỉnh/ Thành phố                int64\n",
            "Quận/ Huyện                   object\n",
            "Mật độ dân số (người/km²)    float64\n",
            "GDPD(%)                      float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OU4ad5AhzJnO",
        "outputId": "ca37ee45-57d8-4c1d-8939-039321b891b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Tỉnh/ Thành phố\n",
              "4     9576\n",
              "8     7950\n",
              "7     1207\n",
              "5      707\n",
              "10     661\n",
              "6      621\n",
              "12     341\n",
              "3      341\n",
              "2      286\n",
              "9      254\n",
              "0      242\n",
              "11     218\n",
              "1      210\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Tỉnh/ Thành phố'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQeiegFpix5v",
        "outputId": "33f956ad-7f57-4f7d-da22-7202bdcfe400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(17540, 12) (5074, 12)\n"
          ]
        }
      ],
      "source": [
        "train_set=pd.read_csv('Train_set.csv')\n",
        "test_set=pd.read_csv('Test_set.csv')\n",
        "print(train_set.shape , test_set.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKhaLdkWVhzW",
        "outputId": "42d40225-4b4c-49d3-f902-049e3020a877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8748, 12) (828, 12)\n"
          ]
        }
      ],
      "source": [
        "train_set=pd.read_csv('HN_train.csv')\n",
        "test_set=pd.read_csv('HN_test.csv')\n",
        "print(train_set.shape , test_set.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "bKRLeKNRjfW0",
        "outputId": "2a04f562-a751-4959-efd8-02c03749e36f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_set\",\n  \"rows\": 17540,\n  \"fields\": [\n    {\n      \"column\": \"H\\u01b0\\u1edbng\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"_\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0110\\u01b0\\u1eddng tr\\u01b0\\u1edbc nh\\u00e0(m)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.067251271224139,\n        \"min\": 0.0,\n        \"max\": 435.0,\n        \"num_unique_values\": 60,\n        \"samples\": [\n          30.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lo\\u1ea1i BDS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ph\\u00e1p l\\u00fd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S\\u1ed1 l\\u1ea7u\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 55,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S\\u1ed1 ph\\u00f2ng ng\\u1ee7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 120,\n        \"num_unique_values\": 45,\n        \"samples\": [\n          60\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gi\\u00e1(T\\u1ef7)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50.09582048856736,\n        \"min\": 0.023,\n        \"max\": 1996.0,\n        \"num_unique_values\": 882,\n        \"samples\": [\n          38.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Di\\u1ec7n t\\u00edch(m2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 129.29942367081722,\n        \"min\": 1.0,\n        \"max\": 982.0,\n        \"num_unique_values\": 617,\n        \"samples\": [\n          175.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T\\u1ec9nh/ Th\\u00e0nh ph\\u1ed1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Qu\\u1eadn/ Huy\\u1ec7n\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 89,\n        \"samples\": [\n          \"H\\u00f3c M\\u00f4n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"M\\u1eadt \\u0111\\u1ed9 d\\u00e2n s\\u1ed1 (ng\\u01b0\\u1eddi/km\\u00b2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115.51889352846338,\n        \"min\": 1.063,\n        \"max\": 996.0,\n        \"num_unique_values\": 89,\n        \"samples\": [\n          4.966\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GDPD(%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.362259825229295,\n        \"min\": -9.28,\n        \"max\": 10.35,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          7.03\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train_set"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-852e158e-88ec-408b-926c-b19400d92b8b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hướng</th>\n",
              "      <th>Đường trước nhà(m)</th>\n",
              "      <th>Loại BDS</th>\n",
              "      <th>Pháp lý</th>\n",
              "      <th>Số lầu</th>\n",
              "      <th>Số phòng ngủ</th>\n",
              "      <th>Giá(Tỷ)</th>\n",
              "      <th>Diện tích(m2)</th>\n",
              "      <th>Tỉnh/ Thành phố</th>\n",
              "      <th>Quận/ Huyện</th>\n",
              "      <th>Mật độ dân số (người/km²)</th>\n",
              "      <th>GDPD(%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>_</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>10.5</td>\n",
              "      <td>60.0</td>\n",
              "      <td>4</td>\n",
              "      <td>Hà Đông</td>\n",
              "      <td>8.021</td>\n",
              "      <td>6.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>_</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>9.1</td>\n",
              "      <td>91.0</td>\n",
              "      <td>10</td>\n",
              "      <td>Sơn Trà</td>\n",
              "      <td>2.483</td>\n",
              "      <td>2.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>_</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>46.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>8</td>\n",
              "      <td>Thủ Đức</td>\n",
              "      <td>4.791</td>\n",
              "      <td>5.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>_</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>11.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>8</td>\n",
              "      <td>Bình Thạnh</td>\n",
              "      <td>23.998</td>\n",
              "      <td>5.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>_</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>11.4</td>\n",
              "      <td>306.0</td>\n",
              "      <td>8</td>\n",
              "      <td>Gò Vấp</td>\n",
              "      <td>34.360</td>\n",
              "      <td>5.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17535</th>\n",
              "      <td>_</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>28.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>4</td>\n",
              "      <td>Long Biên</td>\n",
              "      <td>5.394</td>\n",
              "      <td>6.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17536</th>\n",
              "      <td>_</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>43.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>8</td>\n",
              "      <td>Quận 10</td>\n",
              "      <td>41.196</td>\n",
              "      <td>5.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17537</th>\n",
              "      <td>_</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>9.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>4</td>\n",
              "      <td>Hà Đông</td>\n",
              "      <td>8.021</td>\n",
              "      <td>6.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17538</th>\n",
              "      <td>_</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>11.5</td>\n",
              "      <td>201.0</td>\n",
              "      <td>4</td>\n",
              "      <td>Đông Anh</td>\n",
              "      <td>2.186</td>\n",
              "      <td>6.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17539</th>\n",
              "      <td>_</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>36.0</td>\n",
              "      <td>4</td>\n",
              "      <td>Bắc Từ Liêm</td>\n",
              "      <td>7.529</td>\n",
              "      <td>6.27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17540 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-852e158e-88ec-408b-926c-b19400d92b8b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-852e158e-88ec-408b-926c-b19400d92b8b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-852e158e-88ec-408b-926c-b19400d92b8b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0e3782ce-eedb-46d3-a802-a6bec70ed050\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e3782ce-eedb-46d3-a802-a6bec70ed050')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0e3782ce-eedb-46d3-a802-a6bec70ed050 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e317b9f9-34aa-414a-8efa-03be7cf857ca\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_set')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e317b9f9-34aa-414a-8efa-03be7cf857ca button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_set');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      Hướng  Đường trước nhà(m)  Loại BDS  Pháp lý  Số lầu  Số phòng ngủ  \\\n",
              "0         _                30.0         1        1       6             6   \n",
              "1         _                15.0         1        1       3             4   \n",
              "2         _                30.0         1        1       5             5   \n",
              "3         _                10.0         2        1       3             4   \n",
              "4         _                12.0         2        1       4            16   \n",
              "...     ...                 ...       ...      ...     ...           ...   \n",
              "17535     _                40.0         0        1       4             5   \n",
              "17536     _                15.0         0        0       4             8   \n",
              "17537     _                 7.0         0        1       5             6   \n",
              "17538     _                 4.0         0        1       3             3   \n",
              "17539     _                 5.0         0        0       5             4   \n",
              "\n",
              "       Giá(Tỷ)  Diện tích(m2)  Tỉnh/ Thành phố  Quận/ Huyện  \\\n",
              "0         10.5           60.0                4      Hà Đông   \n",
              "1          9.1           91.0               10      Sơn Trà   \n",
              "2         46.0          180.0                8      Thủ Đức   \n",
              "3         11.0           82.0                8   Bình Thạnh   \n",
              "4         11.4          306.0                8       Gò Vấp   \n",
              "...        ...            ...              ...          ...   \n",
              "17535     28.0          200.0                4    Long Biên   \n",
              "17536     43.0           88.0                8      Quận 10   \n",
              "17537      9.0           77.0                4      Hà Đông   \n",
              "17538     11.5          201.0                4     Đông Anh   \n",
              "17539      3.7           36.0                4  Bắc Từ Liêm   \n",
              "\n",
              "       Mật độ dân số (người/km²)  GDPD(%)  \n",
              "0                          8.021     6.27  \n",
              "1                          2.483     2.58  \n",
              "2                          4.791     5.81  \n",
              "3                         23.998     5.81  \n",
              "4                         34.360     5.81  \n",
              "...                          ...      ...  \n",
              "17535                      5.394     6.27  \n",
              "17536                     41.196     5.81  \n",
              "17537                      8.021     6.27  \n",
              "17538                      2.186     6.27  \n",
              "17539                      7.529     6.27  \n",
              "\n",
              "[17540 rows x 12 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-hCajrCxM4y"
      },
      "outputs": [],
      "source": [
        "def data_proc(choose, train_set, test_set):\n",
        "    train_set.drop('Quận/ Huyện', axis=1, inplace=True)\n",
        "    test_set.drop('Quận/ Huyện', axis=1, inplace=True)\n",
        "\n",
        "    if choose == 1:\n",
        "        # Xử lý dữ liệu bằng cách loại bỏ cột 'Hướng'\n",
        "        train_set.drop('Hướng', axis=1, inplace=True)\n",
        "        test_set.drop('Hướng', axis=1, inplace=True)\n",
        "        print(train_set.shape, test_set.shape)\n",
        "    elif choose == 2:\n",
        "        # Xử lý dữ liệu bằng cách thay dữ liệu khuyết thiếu bằng giá trị ngẫu nhiên, nhưng giữ tỉ lệ\n",
        "        direction_distribution = test_set['Hướng'].value_counts(normalize=True)\n",
        "        random_directions = np.random.choice(direction_distribution.index,\n",
        "                                             size=len(train_set),\n",
        "                                             p=direction_distribution.values)\n",
        "        train_set['Hướng'] = np.random.choice(random_directions, size=len(train_set))\n",
        "        print(train_set.shape, test_set.shape)\n",
        "    elif choose == 3:\n",
        "        # Xử lý dữ liệu bằng cách thay dữ liệu khuyết thiếu bằng giá trị ngẫu nhiên\n",
        "        test_directions = test_set['Hướng'].dropna()\n",
        "        random_directions = np.random.choice(test_directions, size=len(train_set))\n",
        "        train_set['Hướng'].fillna(pd.Series(random_directions, index=train_set.index), inplace=True)\n",
        "        print(train_set.shape, test_set.shape)\n",
        "    elif choose == 4:\n",
        "        # Xử lý dữ liệu bằng cách thay dữ liệu khuyết thiếu bằng giá trị phổ biến nhất\n",
        "        most_common_direction_train = train_set['Hướng'].mode()[0]\n",
        "        train_set['Hướng'].fillna(most_common_direction_train, inplace=True)\n",
        "        test_set['Hướng'].fillna(most_common_direction_train, inplace=True)\n",
        "        print(train_set.shape, test_set.shape)\n",
        "    else:\n",
        "        print('Chọn từ 1-4')\n",
        "\n",
        "    if (choose != 1):\n",
        "      combined = pd.concat([train_set[['Hướng']], test_set[['Hướng']]], axis=0)\n",
        "      encoder = LabelEncoder()\n",
        "      combined['Hướng'] = encoder.fit_transform(combined['Hướng'])\n",
        "      train_set['Hướng'] = combined['Hướng'][:len(train_set)]\n",
        "      test_set['Hướng'] = combined['Hướng'][len(train_set):]\n",
        "\n",
        "    x_train = train_set.drop('Giá(Tỷ)', axis=1)\n",
        "    y_train = train_set['Giá(Tỷ)']\n",
        "    x_test = test_set.drop('Giá(Tỷ)', axis=1)\n",
        "    y_test = test_set['Giá(Tỷ)']\n",
        "    scaler = StandardScaler()\n",
        "    x_train = scaler.fit_transform(x_train)\n",
        "    x_test= scaler.transform(x_test)\n",
        "    return x_train, y_train, x_test,y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDGkB546jLjd",
        "outputId": "2d10e24e-598a-4109-a6b7-00a250665416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(17540, 11) (5074, 11)\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train, x_test,y_test = data_proc(2, train_set, test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGqlqwZi0OTV"
      },
      "source": [
        "#Train Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPL0USh9yAlv"
      },
      "outputs": [],
      "source": [
        "def perform_get(model,x_test,y_test):\n",
        "    y_pred = model.predict(x_test)\n",
        "    # Các chỉ số MAE, RMSE, R2\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    return rmse,mae,r2\n",
        "def show(rmse,mae,r2):\n",
        "  print('RMSE = ',rmse)\n",
        "  print('MAE = ',mae)\n",
        "  print(\"R_Squared = \",r2)\n",
        "  print('+++++++++++++++++++++++++++++++++++++++++\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "dM18Lh211KjS",
        "outputId": "e46d0f63-bc74-486e-b297-5a07a420c040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Regression:\n",
            "Best fit_intercept: True\n",
            "RMSE: 27.996491365078086\n",
            "MAE: 17.975591057214736\n",
            "R^2 Score: -0.31819375502918246\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Linear Regression\n",
        "def train_linear(x_train, x_test, y_train, y_test):\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "    param_grid = {\n",
        "        'fit_intercept': [True, False]\n",
        "    }\n",
        "    model = LinearRegression()\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
        "    grid_search.fit(x_train, y_train)\n",
        "    best_fit_intercept = grid_search.best_params_['fit_intercept']\n",
        "    best_model = LinearRegression(fit_intercept=best_fit_intercept)\n",
        "    best_model.fit(x_train, y_train)\n",
        "    rmse, mae, r2 = perform_get(best_model, x_test, y_test)\n",
        "    print('Linear Regression:')\n",
        "    print('Best fit_intercept:', best_fit_intercept)\n",
        "    print('RMSE:', rmse)\n",
        "    print('MAE:', mae)\n",
        "    print('R^2 Score:', r2)\n",
        "    return best_model\n",
        "\n",
        "train_linear(x_train,x_test,y_train,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTIu9pM0trAG"
      },
      "outputs": [],
      "source": [
        "#Regularize Regression\n",
        "def train_ridge(x_train, x_test, y_train, y_test):\n",
        "    from sklearn.linear_model import Ridge\n",
        "    param_grid = {'alpha': np.logspace(-3, 1, 1000)}\n",
        "    model = Ridge()\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='r2')\n",
        "    grid_search.fit(x_train, y_train)\n",
        "    best_alpha = grid_search.best_params_['alpha']\n",
        "    best_model = Ridge(alpha=best_alpha)\n",
        "    best_model.fit(x_train, y_train)\n",
        "    rmse, mae, r2 = perform_get(best_model, x_test, y_test)\n",
        "    # Lưu lại kết quả cross-validation\n",
        "    cv_results = grid_search.cv_results_\n",
        "    alphas = np.logspace(-3, 1, 1000)\n",
        "    r2_means = cv_results['mean_test_score']\n",
        "    r2_stds = cv_results['std_test_score']\n",
        "    # Vẽ biểu đồ kết quả cross-validation dựa trên R^2 sử dụng line plot\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(alphas, r2_means, marker='o', linestyle='-')\n",
        "    plt.fill_between(alphas, r2_means - r2_stds, r2_means + r2_stds, alpha=0.2)\n",
        "    plt.xscale('log')\n",
        "    plt.xlabel('Alpha')\n",
        "    plt.ylabel('R^2')\n",
        "    plt.title('Cross-validation results based on R^2')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    print('Ridge Regression: best_alpha =', best_alpha)\n",
        "    show(rmse, mae, r2)\n",
        "    return best_model\n",
        "def train_lasso(x_train, x_test, y_train, y_test):\n",
        "    from sklearn.linear_model import Lasso\n",
        "    param_grid = {'alpha': np.logspace(-3, 1, 1000)}\n",
        "    model = Lasso()\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='r2')\n",
        "    grid_search.fit(x_train, y_train)\n",
        "    best_alpha = grid_search.best_params_['alpha']\n",
        "    best_model = Lasso(alpha=best_alpha)\n",
        "    best_model.fit(x_train, y_train)\n",
        "    rmse, mae, r2 = perform_get(best_model, x_test, y_test)\n",
        "    # Lưu lại kết quả cross-validation\n",
        "    cv_results = grid_search.cv_results_\n",
        "    alphas = np.logspace(-3, 1, 1000)\n",
        "    r2_means = cv_results['mean_test_score']\n",
        "    r2_stds = cv_results['std_test_score']\n",
        "    # Vẽ biểu đồ kết quả cross-validation dựa trên R^2 sử dụng line plot\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(alphas, r2_means, marker='o', linestyle='-')\n",
        "    plt.fill_between(alphas, r2_means - r2_stds, r2_means + r2_stds, alpha=0.2)\n",
        "    plt.xscale('log')\n",
        "    plt.xlabel('Alpha')\n",
        "    plt.ylabel('R^2')\n",
        "    plt.title('Cross-validation results based on R^2 (Lasso)')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    print('Lasso Regression: best_alpha =', best_alpha)\n",
        "    show(rmse, mae, r2)\n",
        "    return best_model\n",
        "def train_elastic_net(x_train, x_test, y_train, y_test):\n",
        "    from sklearn.linear_model import ElasticNet\n",
        "    param_grid = {'alpha': np.logspace(-3, 1, 100), 'l1_ratio': [0.01, 0.1,0,2, 0.5]}\n",
        "    model = ElasticNet()\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='r2')\n",
        "    grid_search.fit(x_train, y_train)\n",
        "    best_alpha = grid_search.best_params_['alpha']\n",
        "    best_l1_ratio = grid_search.best_params_['l1_ratio']\n",
        "    best_model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
        "    best_model.fit(x_train, y_train)\n",
        "    rmse, mae, r2 = perform_get(best_model, x_test, y_test)\n",
        "    # Lưu lại kết quả cross-validation\n",
        "    cv_results = grid_search.cv_results_\n",
        "    alphas = np.logspace(-3, 1, 500)\n",
        "    r2_means = cv_results['mean_test_score']\n",
        "    # Ensure that the lengths of alphas and r2_means are consistent for plotting\n",
        "    alphas = alphas[:len(r2_means)]\n",
        "    # Vẽ biểu đồ kết quả cross-validation dựa trên R^2 sử dụng line plot\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(alphas, r2_means, marker='o', linestyle='-')\n",
        "    plt.xscale('log')\n",
        "    plt.xlabel('Alpha')\n",
        "    plt.ylabel('R^2')\n",
        "    plt.title('Cross-validation results based on R^2 (Elastic Net)')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    print('Elastic Net Regression: best_alpha =', best_alpha, ', best_l1_ratio =', best_l1_ratio)\n",
        "    show(rmse, mae, r2)\n",
        "    return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "839Ar-ewkiOF",
        "outputId": "dcf2fc42-a13b-4f84-da66-c200798bbe7e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ridge Regression: best_alpha = 10.0\n",
            "RMSE =  27.987911784002087\n",
            "MAE =  17.970378806868496\n",
            "R_Squared =  -0.31738595257061775\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lasso Regression: best_alpha = 0.5791122647641759\n",
            "RMSE =  27.40714212173628\n",
            "MAE =  17.429396925078365\n",
            "R_Squared =  -0.26327976337945747\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.5791122647641759)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.5791122647641759)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "Lasso(alpha=0.5791122647641759)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ridge(x_train, x_test, y_train, y_test)\n",
        "train_lasso(x_train, x_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j4HMYqwTg_yF",
        "outputId": "ee9f6e8c-f6b1-422b-aa1e-6048cefeb87b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.147e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.147e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.147e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.147e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.147e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.147e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.150e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.344e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.150e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.344e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.150e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.344e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.150e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.151e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.150e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.151e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.346e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.150e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.151e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.266e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.346e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.151e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.205e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.266e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.151e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.205e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.267e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.206e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.348e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.206e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.349e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.269e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.349e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.208e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.350e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.351e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.156e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.210e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.156e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.211e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.212e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.354e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.275e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.356e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.277e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.357e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.163e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.216e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.358e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.162e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.280e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.360e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.282e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.222e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.170e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.286e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.226e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.288e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.368e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.175e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.171e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.178e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.231e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.173e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.175e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.296e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.178e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.299e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.380e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.241e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.303e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.383e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.191e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.245e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.306e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.195e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.249e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.310e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.391e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.315e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.396e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.194e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.324e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.335e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.226e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.280e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.211e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.233e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.286e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.348e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.429e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.240e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.222e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.436e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.228e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.370e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.451e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.316e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.241e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.378e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.324e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.386e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.468e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.395e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.477e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.404e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.487e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.414e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.496e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.311e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.363e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.279e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.507e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.287e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.434e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.332e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.385e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.296e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.445e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.528e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.344e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.396e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.306e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.356e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.408e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.315e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.467e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.551e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.368e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.479e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.562e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.380e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.335e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.490e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.574e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.393e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.502e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.586e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.514e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.526e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.610e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.483e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.622e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.496e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.549e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.634e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.509e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.397e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.561e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.646e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.522e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.408e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.572e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.658e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.483e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.535e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.669e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.496e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.547e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.595e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.680e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.508e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.605e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.691e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.521e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.572e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.616e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.702e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.626e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.712e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.544e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.596e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.467e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.635e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.722e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.556e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.477e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.645e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.732e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.567e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.618e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.654e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.741e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.577e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.628e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.494e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.662e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.750e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.588e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.639e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.502e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.670e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.758e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.648e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.678e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.766e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.658e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.518e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.685e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.774e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.615e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.525e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.692e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.781e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.624e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.675e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.787e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.632e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.683e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.794e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.639e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.690e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.544e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.800e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.646e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.697e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.549e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.715e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.653e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.555e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.720e+07, tolerance: 3.556e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+07, tolerance: 3.741e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.659e+07, tolerance: 3.468e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e+07, tolerance: 3.569e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e+07, tolerance: 3.240e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "500 fits failed out of a total of 2500.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "500 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py\", line 892, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'l1_ratio' parameter of ElasticNet must be a float in the range [0, 1]. Got 2 instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.26922617 0.26922208 0.26922663        nan 0.26920383 0.26923122\n",
            " 0.26922674 0.26923172        nan 0.26920673 0.26923675 0.26923184\n",
            " 0.2692373         nan 0.26920991 0.26924281 0.26923743 0.26924341\n",
            "        nan 0.2692134  0.26924945 0.26924356 0.2692501         nan\n",
            " 0.26921723 0.26925672 0.26925027 0.26925743        nan 0.26922142\n",
            " 0.26926467 0.26925761 0.26926546        nan 0.26922601 0.26927338\n",
            " 0.26926566 0.26927424        nan 0.26923105 0.26928291 0.26927446\n",
            " 0.26928385        nan 0.26923656 0.26929333 0.26928409 0.26929436\n",
            "        nan 0.26924261 0.26930473 0.26929462 0.26930585        nan\n",
            " 0.26924924 0.26931719 0.26930614 0.26931842        nan 0.26925649\n",
            " 0.26933081 0.26931874 0.26933215        nan 0.26926443 0.26934568\n",
            " 0.2693325  0.26934714        nan 0.26927312 0.26936191 0.26934753\n",
            " 0.26936351        nan 0.26928263 0.26937963 0.26936394 0.26938137\n",
            "        nan 0.26929305 0.26939895 0.26938184 0.26940084        nan\n",
            " 0.26930444 0.26942    0.26940136 0.26942206        nan 0.26931689\n",
            " 0.26944292 0.26942264 0.26944517        nan 0.2693305  0.26946787\n",
            " 0.2694458  0.26947031        nan 0.26934535 0.26949499 0.26947101\n",
            " 0.26949763        nan 0.26936159 0.26952444 0.26949842 0.26952731\n",
            "        nan 0.2693793  0.26955635 0.26952818 0.26955951        nan\n",
            " 0.26939864 0.26959097 0.26955997 0.26959439        nan 0.26941972\n",
            " 0.26962844 0.26959491 0.26963213        nan 0.26944268 0.26966879\n",
            " 0.26963272 0.26967291        nan 0.2694677  0.26971245 0.26967218\n",
            " 0.26971688        nan 0.2694949  0.26975946 0.26971612 0.26976422\n",
            "        nan 0.2695245  0.26980996 0.26976342 0.26981507        nan\n",
            " 0.26955475 0.26986409 0.26981424 0.26986955        nan 0.26958737\n",
            " 0.26992195 0.26986871 0.26992778        nan 0.26962424 0.26998362\n",
            " 0.26992692 0.26998981        nan 0.26966049 0.27004911 0.26998894\n",
            " 0.27005566        nan 0.26969964 0.27011838 0.2700548  0.27012529\n",
            "        nan 0.26974186 0.27019131 0.27012445 0.27019856        nan\n",
            " 0.26979125 0.27026769 0.27019777 0.27027525        nan 0.26984423\n",
            " 0.27034719 0.27027454 0.27035501        nan 0.26990095 0.27042932\n",
            " 0.27035442 0.27043735        nan 0.2699616  0.27051341 0.2704369\n",
            " 0.27052157        nan 0.27002598 0.27059859 0.27052131 0.27060678\n",
            "        nan 0.27009424 0.27068372 0.27060677 0.2706918         nan\n",
            " 0.27016637 0.27076736 0.27069206 0.27077517        nan 0.27024213\n",
            " 0.27084769 0.2707758  0.27085503        nan 0.27032118 0.2709225\n",
            " 0.27085612 0.27092912        nan 0.27040325 0.27098906 0.27093076\n",
            " 0.27099467        nan 0.27048767 0.27104411 0.27099692 0.27104835\n",
            "        nan 0.27057371 0.27108371 0.27105136 0.27108616        nan\n",
            " 0.27066023 0.27110323 0.27108999 0.27110339        nan 0.27074604\n",
            " 0.2710972  0.27110812 0.27109448        nan 0.27083058 0.27105922\n",
            " 0.27110029 0.27105295        nan 0.27091088 0.27098191 0.27105988\n",
            " 0.27097132        nan 0.2709842  0.27085677 0.27097952 0.27084099\n",
            "        nan 0.27104742 0.27067412 0.27085044 0.27065215        nan\n",
            " 0.27109678 0.270423   0.27066281 0.27039372        nan 0.27112777\n",
            " 0.27009111 0.27040549 0.27005327        nan 0.27113506 0.26966473\n",
            " 0.27006614 0.26961698        nan 0.27111254 0.26912875 0.26963061\n",
            " 0.2690696         nan 0.27105236 0.26846661 0.26908355 0.26839444\n",
            "        nan 0.27094643 0.26765863 0.26840674 0.26757343        nan\n",
            " 0.27078485 0.26668886 0.26757672 0.26658718        nan 0.27055636\n",
            " 0.26553519 0.26658075 0.2654151         nan 0.27024552 0.26417603\n",
            " 0.26540213 0.26403555        nan 0.2698331  0.26258895 0.2640168\n",
            " 0.26242609        nan 0.26931078 0.2607509  0.2623994  0.26056372\n",
            "        nan 0.26866353 0.25863875 0.26052667 0.25842525        nan\n",
            " 0.26788031 0.25622935 0.25837472 0.25598768        nan 0.26692997\n",
            " 0.25350019 0.25591988 0.25322861        nan 0.26578994 0.25042976\n",
            " 0.25313919 0.25012679        nan 0.26443892 0.24699824 0.25001063\n",
            " 0.24666265        nan 0.26286267 0.24318807 0.24651406 0.24281882\n",
            "        nan 0.26102428 0.23898436 0.24263131 0.23858081        nan\n",
            " 0.25889616 0.23437544 0.23834694 0.23393752        nan 0.25645033\n",
            " 0.22935386 0.23365257 0.22888186        nan 0.2536583  0.22391651\n",
            " 0.22853941 0.22341126        nan 0.25049584 0.21806523 0.2230023\n",
            " 0.21752813        nan 0.24694433 0.21180716 0.21704294 0.21124024\n",
            "        nan 0.24297299 0.20515708 0.21067372 0.20456091        nan\n",
            " 0.23855318 0.19813383 0.20391168 0.19750914        nan 0.23366917\n",
            " 0.19075517 0.19676565 0.19010956        nan 0.2283183  0.1830545\n",
            " 0.18925969 0.18239212        nan 0.22247219 0.17507012 0.18142338\n",
            " 0.17439175        nan 0.21612266 0.16683999 0.17329143 0.16614774\n",
            "        nan 0.20927913 0.15839767 0.16490319 0.15770304        nan\n",
            " 0.20195621 0.14979496 0.15629999 0.14910337        nan 0.19415012\n",
            " 0.14107941 0.14752839 0.14039636        nan 0.18588113 0.13229957\n",
            " 0.13864082 0.13163051        nan 0.17717664 0.12350401 0.12969252\n",
            " 0.12285422        nan 0.16806763 0.11474032 0.12072764 0.11411485\n",
            "        nan 0.15858992 0.10605435 0.11179267 0.10545785        nan\n",
            " 0.14875092 0.09748923 0.10293443 0.09692594        nan 0.13862284\n",
            " 0.08908474 0.09419814 0.08855849        nan 0.12838639 0.08087692\n",
            " 0.08562434 0.08039097        nan 0.1180749  0.07289979 0.07725399\n",
            " 0.07245461        nan 0.10764538 0.06517816 0.06911588 0.06477616\n",
            "        nan 0.09729279 0.05773469 0.06123688 0.05737778        nan\n",
            " 0.08692222 0.05058651 0.05364039 0.05027713        nan 0.07674005\n",
            " 0.04374848 0.04634681 0.04348744        nan 0.06664571 0.03723035\n",
            " 0.03936782 0.03701781        nan 0.05669736 0.03103779 0.03271076\n",
            " 0.03087347        nan 0.04695378 0.0251729  0.02638537 0.02505617\n",
            "        nan 0.03745928]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elastic Net Regression: best_alpha = 0.15199110829529347 , best_l1_ratio = 0.5\n",
            "RMSE =  26.930814180136597\n",
            "MAE =  17.314231389810427\n",
            "R_Squared =  -0.21975049239298516\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet(alpha=0.15199110829529347)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=0.15199110829529347)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "ElasticNet(alpha=0.15199110829529347)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_elastic_net(x_train, x_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SKsVaWyu2H-Q"
      },
      "outputs": [],
      "source": [
        "#Kernel Regression\n",
        "def train_svm(x_train, x_test, y_train, y_test):\n",
        "    from sklearn.svm import SVR\n",
        "    param_grid = {'C': np.logspace(-3, 3,7), 'gamma': np.logspace(-3, 3,7)}\n",
        "    model = SVR()\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
        "    grid_search.fit(x_train, y_train)\n",
        "    best_params = grid_search.best_params_\n",
        "    best_model = SVR(C=best_params['C'], gamma=best_params['gamma'])\n",
        "    best_model.fit(x_train, y_train)\n",
        "    rmse, mae, r2 = perform_get(best_model, x_test, y_test)  # Assuming perform_get is defined elsewhere\n",
        "    # Lưu lại kết quả cross-validation\n",
        "    cv_results = grid_search.cv_results_\n",
        "    Cs = np.logspace(-3, 3, 7)\n",
        "    gammas = np.logspace(-3, 3, 7)\n",
        "    mean_scores = np.array(cv_results['mean_test_score']).reshape(len(Cs), len(gammas))\n",
        "    # Vẽ biểu đồ 3D của kết quả cross-validation dựa trên MAE\n",
        "    fig = plt.figure(figsize=(10, 5))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "    X, Y = np.meshgrid(Cs, gammas)\n",
        "    ax.plot_surface(np.log10(X), np.log10(Y), mean_scores, cmap='viridis', alpha=0.8)\n",
        "    ax.set_xlabel('log10(C)')\n",
        "    ax.set_ylabel('log10(gamma)')\n",
        "    ax.set_zlabel('Negative MAE')\n",
        "    ax.set_title('Cross-validation results for SVR')\n",
        "    plt.show()\n",
        "    print('SVM Regression')\n",
        "    print('SVR: best_C =', best_params['C'], ', best_gamma =', best_params['gamma'])\n",
        "    show(rmse, mae, r2)  # Assuming show is defined elsewhere\n",
        "    return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63zsz3Twku3U"
      },
      "outputs": [],
      "source": [
        "train_svm(x_train, x_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvccYRGE3JrQ"
      },
      "outputs": [],
      "source": [
        "#Tree-Based Regression\n",
        "def train_decision_tree(x_train, x_test, y_train, y_test, max_depth=None):\n",
        "    from sklearn.tree import DecisionTreeRegressor\n",
        "    param_grid = {'max_depth': [None, 10, 20, 30, 40, 50]}\n",
        "    model = DecisionTreeRegressor()\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring=['neg_mean_absolute_error', 'r2'], refit='r2')\n",
        "    grid_search.fit(x_train, y_train)\n",
        "    best_max_depth = grid_search.best_params_['max_depth']\n",
        "    best_model = DecisionTreeRegressor(max_depth=best_max_depth)\n",
        "    best_model.fit(x_train, y_train)\n",
        "    mae, rmse, r2 = perform_get(best_model, x_test, y_test)\n",
        "    print('Decision Tree Regression:')\n",
        "    print('Best max_depth:', best_max_depth)\n",
        "    show(mae, rmse, r2)\n",
        "    return best_model\n",
        "\n",
        "def train_random_forest(x_train, x_test, y_train, y_test, n_estimators=100, max_depth=None):\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "    param_grid = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20, 30, 40, 50]}\n",
        "    model = RandomForestRegressor()\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring=['neg_mean_absolute_error', 'r2'], refit='r2')\n",
        "    grid_search.fit(x_train, y_train)\n",
        "    best_n_estimators = grid_search.best_params_['n_estimators']\n",
        "    best_max_depth = grid_search.best_params_['max_depth']\n",
        "    best_model = RandomForestRegressor(n_estimators=best_n_estimators, max_depth=best_max_depth)\n",
        "    best_model.fit(x_train, y_train)\n",
        "    mae, rmse, r2 = perform_get(best_model, x_test, y_test)\n",
        "    print('Random Forest Regression:')\n",
        "    print('Best n_estimators:', best_n_estimators)\n",
        "    print('Best max_depth:', best_max_depth)\n",
        "    show(mae, rmse, r2)\n",
        "    return best_model\n",
        "\n",
        "def train_xgboost(x_train, x_test, y_train, y_test, max_depth=None, n_estimators=100):\n",
        "    from xgboost import XGBRegressor\n",
        "    param_grid = {\n",
        "        'max_depth': [3, 6, 9],\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'learning_rate': [0.01, 0.1, 0.3]\n",
        "    }\n",
        "    model = XGBRegressor()\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring=['neg_mean_absolute_error', 'r2'], refit='r2')\n",
        "    grid_search.fit(x_train, y_train)\n",
        "    best_params = grid_search.best_params_\n",
        "    best_model = XGBRegressor(max_depth=best_params['max_depth'], n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'])\n",
        "    best_model.fit(x_train, y_train)\n",
        "    mae, rmse, r2 = perform_get(best_model, x_test, y_test)\n",
        "    print('XGBoost Regression:')\n",
        "    print('Best max_depth:', best_params['max_depth'])\n",
        "    print('Best n_estimators:', best_params['n_estimators'])\n",
        "    print('Best learning_rate:', best_params['learning_rate'])\n",
        "    show(mae, rmse, r2)\n",
        "    return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9Cly58nkxod"
      },
      "outputs": [],
      "source": [
        "train_decision_tree(x_train, x_test, y_train, y_test, max_depth=None)\n",
        "train_random_forest(x_train, x_test, y_train, y_test, n_estimators=100, max_depth=None)\n",
        "train_xgboost(x_train, x_test, y_train, y_test, max_depth=None, n_estimators=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0ffjjmlf5TT"
      },
      "outputs": [],
      "source": [
        "def train_catboost_regression(x_train, x_test, y_train, y_test):\n",
        "    # Tạo mô hình CatBoost Regression\n",
        "    from catboost import CatBoostRegressor\n",
        "    model = CatBoostRegressor(verbose=0)\n",
        "    # Tạo grid search cho các siêu tham số\n",
        "    param_grid = {\n",
        "        'learning_rate': [0.01, 0.1, 0.3],  # Các giá trị learning_rate để kiểm tra\n",
        "        'depth': [6, 8, 10]  # Các giá trị depth để kiểm tra\n",
        "    }\n",
        "    grid_search = GridSearchCV(model, param_grid, scoring='r2', cv=5)\n",
        "    # Huấn luyện mô hình\n",
        "    grid_search.fit(x_train, y_train)\n",
        "    # Dự đoán trên tập kiểm tra\n",
        "    y_pred = grid_search.predict(x_test)\n",
        "    # Tính toán R^2\n",
        "    r2 = grid_search.score(x_test, y_test)\n",
        "    # Tính toán RMSE và MAE\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    # Vẽ biểu đồ dự đoán và thực tế\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(y_test, y_pred, color='blue')\n",
        "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red')\n",
        "    plt.title('Actual vs Predicted (CatBoost Regression)')\n",
        "    plt.xlabel('Actual')\n",
        "    plt.ylabel('Predicted')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    # Hiển thị giá trị R^2, RMSE và MAE\n",
        "    print('Catboost Regression')\n",
        "    print(\"Best parameters:\", grid_search.best_params_)\n",
        "    print(\"R^2 score:\", r2)\n",
        "    print(\"RMSE:\", rmse)\n",
        "    print(\"MAE:\", mae)\n",
        "    # Trả về mô hình tốt nhất từ grid search\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "def train_lightgbm_regression(x_train, x_test, y_train, y_test):\n",
        "    # Tạo mô hình LightGBM Regression\n",
        "    import lightgbm as lgb\n",
        "    model = lgb.LGBMRegressor()\n",
        "    # Tạo grid search cho các siêu tham số\n",
        "    param_grid = {\n",
        "        'learning_rate': [0.01, 0.1, 0.3],  # Các giá trị learning_rate để kiểm tra\n",
        "        'max_depth': [6, 8, 10]  # Các giá trị max_depth để kiểm tra\n",
        "    }\n",
        "    grid_search = GridSearchCV(model, param_grid, scoring='r2', cv=5)\n",
        "    # Huấn luyện mô hình\n",
        "    grid_search.fit(x_train, y_train)\n",
        "    # Dự đoán trên tập kiểm tra\n",
        "    y_pred = grid_search.predict(x_test)\n",
        "    # Tính toán R^2\n",
        "    r2 = grid_search.score(x_test, y_test)\n",
        "    # Tính toán RMSE và MAE\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    # Vẽ biểu đồ dự đoán và thực tế\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(y_test, y_pred, color='blue')\n",
        "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red')\n",
        "    plt.title('Actual vs Predicted (LightGBM Regression)')\n",
        "    plt.xlabel('Actual')\n",
        "    plt.ylabel('Predicted')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    # Hiển thị giá trị R^2, RMSE và MAE\n",
        "    print('Light GBM Regression')\n",
        "    print(\"Best parameters:\", grid_search.best_params_)\n",
        "    print(\"R^2 score:\", r2)\n",
        "    print(\"RMSE:\", rmse)\n",
        "    print(\"MAE:\", mae)\n",
        "    # Trả về mô hình tốt nhất từ grid search\n",
        "    return grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wK4GKA-lSDi"
      },
      "outputs": [],
      "source": [
        "train_lightgbm_regression(x_train, x_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlPVbXXVhiRu"
      },
      "outputs": [],
      "source": [
        "train_catboost_regression(x_train, x_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFz24jSvlHJx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import RANSACRegressor, HuberRegressor, TheilSenRegressor\n",
        "\n",
        "def train_ransac_regression(x_train, x_test, y_train, y_test):\n",
        "    # Tạo mô hình RANSAC Regression\n",
        "    model = RANSACRegressor()\n",
        "    # Tạo grid search cho các siêu tham số\n",
        "    param_grid = {\n",
        "        'min_samples': [0.1, 0.2, 0.3],  # Các giá trị min_samples để kiểm tra\n",
        "        'max_trials': [50, 100, 150]  # Các giá trị max_trials để kiểm tra\n",
        "    }\n",
        "    grid_search = GridSearchCV(model, param_grid, scoring='r2', cv=5)\n",
        "    # Huấn luyện mô hình\n",
        "    grid_search.fit(x_train, y_train)\n",
        "    # Dự đoán trên tập kiểm tra\n",
        "    y_pred = grid_search.predict(x_test)\n",
        "    # Tính toán R^2\n",
        "    r2 = grid_search.score(x_test, y_test)\n",
        "    # Tính toán RMSE và MAE\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    # Vẽ biểu đồ dự đoán và thực tế\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(y_test, y_pred, color='blue')\n",
        "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red')\n",
        "    plt.title('Actual vs Predicted (RANSAC Regression)')\n",
        "    plt.xlabel('Actual')\n",
        "    plt.ylabel('Predicted')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    # Hiển thị giá trị R^2, RMSE và MAE\n",
        "    print('RANSAC Regression')\n",
        "    print(\"Best parameters:\", grid_search.best_params_)\n",
        "    print(\"R^2 score:\", r2)\n",
        "    print(\"RMSE:\", rmse)\n",
        "    print(\"MAE:\", mae)\n",
        "    # Trả về mô hình tốt nhất từ grid search\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "def train_huber_regression(x_train, x_test, y_train, y_test):\n",
        "    # Tạo mô hình Huber Regression\n",
        "    model = HuberRegressor()\n",
        "    # Tạo grid search cho các siêu tham số\n",
        "    param_grid = {\n",
        "        'epsilon': [1.0, 1.5, 2.0],  # Các giá trị epsilon để kiểm tra\n",
        "        'alpha': [0.0001, 0.001, 0.01]  # Các giá trị alpha để kiểm tra\n",
        "    }\n",
        "    grid_search = GridSearchCV(model, param_grid, scoring='r2', cv=5)\n",
        "    # Huấn luyện mô hình\n",
        "    grid_search.fit(x_train, y_train)\n",
        "    # Dự đoán trên tập kiểm tra\n",
        "    y_pred = grid_search.predict(x_test)\n",
        "    # Tính toán R^2\n",
        "    r2 = grid_search.score(x_test, y_test)\n",
        "    # Tính toán RMSE và MAE\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    # Vẽ biểu đồ dự đoán và thực tế\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(y_test, y_pred, color='blue')\n",
        "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red')\n",
        "    plt.title('Actual vs Predicted (Huber Regression)')\n",
        "    plt.xlabel('Actual')\n",
        "    plt.ylabel('Predicted')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    # Hiển thị giá trị R^2, RMSE và MAE\n",
        "    print('Huber Regression')\n",
        "    print(\"Best parameters:\", grid_search.best_params_)\n",
        "    print(\"R^2 score:\", r2)\n",
        "    print(\"RMSE:\", rmse)\n",
        "    print(\"MAE:\", mae)\n",
        "    # Trả về mô hình tốt nhất từ grid search\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "def train_theil_sen_regression(x_train, x_test, y_train, y_test):\n",
        "    # Tạo mô hình Theil-Sen Regression\n",
        "    model = TheilSenRegressor()\n",
        "    # Không có các siêu tham số để tinh chỉnh trong Theil-Sen Regression\n",
        "    # Huấn luyện mô hình\n",
        "    model.fit(x_train, y_train)\n",
        "    # Dự đoán trên tập kiểm tra\n",
        "    y_pred = model.predict(x_test)\n",
        "    # Tính toán R^2\n",
        "    r2 = model.score(x_test, y_test)\n",
        "    # Tính toán RMSE và MAE\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    # Vẽ biểu đồ dự đoán và thực tế\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(y_test, y_pred, color='blue')\n",
        "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red')\n",
        "    plt.title('Actual vs Predicted (Theil-Sen Regression)')\n",
        "    plt.xlabel('Actual')\n",
        "    plt.ylabel('Predicted')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    # Hiển thị giá trị R^2, RMSE và MAE\n",
        "    print('Theil-Sen Regression')\n",
        "    print(\"R^2 score:\", r2)\n",
        "    print(\"RMSE:\", rmse)\n",
        "    print(\"MAE:\", mae)\n",
        "    # Trả về mô hình Theil-Sen Regression\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQD1oSY0lmVj"
      },
      "outputs": [],
      "source": [
        "train_ransac_regression(x_train, x_test, y_train, y_test)\n",
        "train_huber_regression(x_train, x_test, y_train, y_test)\n",
        "train_theil_sen_regression(x_train, x_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwaqhZMsNLvt"
      },
      "source": [
        "#Huấn luyện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGmi7ei0LFMs"
      },
      "outputs": [],
      "source": [
        "def train_models(x_train,x_test,y_train,y_test):\n",
        "  print(\"LinearRegression\")\n",
        "  train_linear(x_train,x_test,y_train,y_test)\n",
        "\n",
        "  print(\"Ridge\")\n",
        "  train_Ridge_Lasso(x_train, x_test, y_train, y_test, model_type='ridge', alpha=1.0)\n",
        "\n",
        "  print(\"Lasso\")\n",
        "  train_Ridge_Lasso(x_train, x_test, y_train, y_test, model_type='lasso', alpha=1.0)\n",
        "\n",
        "  print(\"SVM(SVR)\")\n",
        "  train_SVM(x_train, x_test, y_train, y_test, kernel='linear', C=1.0, epsilon=0.1)\n",
        "  print(\"DecisionTree\")\n",
        "  for max_depth in range(1,6):\n",
        "    print(\"độ sâu = \",max_depth)\n",
        "    train_tree(x_train, x_test, y_train, y_test, model_type='decision_tree', max_depth=max_depth, n_estimators=100)\n",
        "  print(\"RandomForest\")\n",
        "  for max_depth in range(1,6):\n",
        "    print(\"độ sâu = \",max_depth)\n",
        "    train_tree(x_train, x_test, y_train, y_test, model_type='random_forest', max_depth=max_depth, n_estimators=100)\n",
        "\n",
        "  print(\"XGboost\")\n",
        "  train_xgb(x_train, x_test, y_train, y_test, max_depth=3, learning_rate=0.1, n_estimators=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8Ip7-qZQ7DJ",
        "outputId": "6f9cda01-7528-4efd-b63b-07a13c93662d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LinearRegression\n",
            "MSE =  778.5433416228562\n",
            "RMSE =  27.902389532490872\n",
            "MAE =  17.889571172129905\n",
            "R_Squared =  -0.30934721941999843\n",
            "MAPE =  2.0062783529092347\n",
            "Cost time =  0.012195825576782227\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "Ridge\n",
            "MSE =  778.4958648065854\n",
            "RMSE =  27.90153875338393\n",
            "MAE =  17.88908050497609\n",
            "R_Squared =  -0.30926737333558973\n",
            "MAPE =  2.006207593365061\n",
            "Cost time =  0.008466720581054688\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "Lasso\n",
            "MSE =  736.7058777690916\n",
            "RMSE =  27.142326314615914\n",
            "MAE =  17.208299789198712\n",
            "R_Squared =  -0.2389853474009993\n",
            "MAPE =  1.8277980649634038\n",
            "Cost time =  0.006628513336181641\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "SVM(SVR)\n",
            "MSE =  604.8462723423851\n",
            "RMSE =  24.59362259494085\n",
            "MAE =  13.47150174927109\n",
            "R_Squared =  -0.017225043909878\n",
            "MAPE =  1.4132397809394008\n",
            "Cost time =  14.962247133255005\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "DecisionTree\n",
            "độ sâu =  1\n",
            "MSE =  1025.4967750512883\n",
            "RMSE =  32.02337857021473\n",
            "MAE =  20.27638596578947\n",
            "R_Squared =  -0.7246712920807807\n",
            "MAPE =  2.713645704090611\n",
            "Cost time =  0.006808042526245117\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "độ sâu =  2\n",
            "MSE =  938.9966758023598\n",
            "RMSE =  30.643052651496063\n",
            "MAE =  18.642069927427208\n",
            "R_Squared =  -0.5791961998462838\n",
            "MAPE =  2.5281649831975943\n",
            "Cost time =  0.011874914169311523\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "độ sâu =  3\n",
            "MSE =  856.207233254835\n",
            "RMSE =  29.261019005749528\n",
            "MAE =  16.660527474448266\n",
            "R_Squared =  -0.4399616568201039\n",
            "MAPE =  1.9779861991354326\n",
            "Cost time =  0.011845111846923828\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "độ sâu =  4\n",
            "MSE =  771.1055981700614\n",
            "RMSE =  27.76878820132527\n",
            "MAE =  14.518695305770962\n",
            "R_Squared =  -0.2968384890924405\n",
            "MAPE =  1.7775482917831422\n",
            "Cost time =  0.015897274017333984\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "độ sâu =  5\n",
            "MSE =  686.9021709472631\n",
            "RMSE =  26.20881857213833\n",
            "MAE =  13.061566903009561\n",
            "R_Squared =  -0.1552259193028278\n",
            "MAPE =  1.6386346142788006\n",
            "Cost time =  0.0222320556640625\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "RandomForest\n",
            "độ sâu =  1\n",
            "MSE =  923.4823218752786\n",
            "RMSE =  30.388851934143194\n",
            "MAE =  19.537124259531442\n",
            "R_Squared =  -0.5531042983560235\n",
            "MAPE =  2.6477883325696148\n",
            "Cost time =  0.4120173454284668\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "độ sâu =  2\n",
            "MSE =  903.1818331567271\n",
            "RMSE =  30.052983764623555\n",
            "MAE =  18.402168817180893\n",
            "R_Squared =  -0.5189631182373979\n",
            "MAPE =  2.491494358383061\n",
            "Cost time =  0.5956249237060547\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "độ sâu =  3\n",
            "MSE =  837.6526443984463\n",
            "RMSE =  28.94222943034013\n",
            "MAE =  16.78859822966448\n",
            "R_Squared =  -0.408756715453638\n",
            "MAPE =  2.04460445354995\n",
            "Cost time =  0.8155536651611328\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "độ sâu =  4\n",
            "MSE =  688.8798873372424\n",
            "RMSE =  26.246521433082183\n",
            "MAE =  14.689056551099869\n",
            "R_Squared =  -0.1585520250153536\n",
            "MAPE =  1.8410296659469572\n",
            "Cost time =  1.363100528717041\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "độ sâu =  5\n",
            "MSE =  549.9049725847152\n",
            "RMSE =  23.450052720297137\n",
            "MAE =  12.701652023033912\n",
            "R_Squared =  0.07517474197625407\n",
            "MAPE =  1.6067786742070784\n",
            "Cost time =  1.5069034099578857\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n",
            "XGboost\n",
            "MSE =  325.59499528678975\n",
            "RMSE =  18.044251031472317\n",
            "MAE =  8.49841692498246\n",
            "R_Squared =  0.4524172529082612\n",
            "MAPE =  0.7323862367623492\n",
            "Cost time =  0.07932138442993164\n",
            "+++++++++++++++++++++++++++++++++++++++++\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_models(x_train,x_test,y_train,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_O-jTWBYr1B"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}